{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Callable, Dict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import re\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import OrderedDict\n",
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from functools import partial\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (121740, 4)\n",
      "Test data size: (7189, 4)\n",
      "Validation data size: (7165, 4)\n",
      "Classes distribution:\n",
      "1    89389\n",
      "0    32351\n",
      "Name: Label, dtype: int64\n",
      "Some train examples:                                             Claim  \\\n",
      "0  Chris Hemsworth appeared in A Perfect Getaway.   \n",
      "1                         Roald Dahl is a writer.   \n",
      "2                       Roald Dahl is a governor.   \n",
      "\n",
      "                                            Evidence  ID  Label  \n",
      "0  2\\tHemsworth has also appeared in the science ...   3      1  \n",
      "1  0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...   7      1  \n",
      "2  0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...   8      0  \n",
      "Some test examples:                                                Claim  \\\n",
      "0    Anxiety has been linked with physical symptoms.   \n",
      "1                         Firefox is an application.   \n",
      "2  Keegan-Michael Key played President Barack Oba...   \n",
      "\n",
      "                                            Evidence     ID  Label  \n",
      "0  13\\tFurthermore , anxiety has been linked with...  16387      1  \n",
      "1  0\\tMozilla Firefox -LRB- or simply Firefox -RR...      6      1  \n",
      "2  6\\tIn 2015 , Key appeared at the White House C...  16392      1  \n",
      "Some validation examples:                                                Claim  \\\n",
      "0  The Indian Army comprises part of the country'...   \n",
      "1                         Recovery features Rihanna.   \n",
      "2                            Rihanna is on Recovery.   \n",
      "\n",
      "                                            Evidence     ID  Label  \n",
      "0  16\\tIt is an all-volunteer force and comprises...  98304      1  \n",
      "1  6\\tEminem also collaborated with artists such ...  98305      1  \n",
      "2  6\\tEminem also collaborated with artists such ...  98306      1  \n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "trainData = pd.read_csv('./fever_data/train_pairs.csv')\n",
    "testData = pd.read_csv('./fever_data/test_pairs.csv')\n",
    "valData = pd.read_csv('./fever_data/val_pairs.csv')\n",
    "\n",
    "#drop first column\n",
    "trainData = trainData.drop(trainData.columns[0], axis=1)\n",
    "valData = valData.drop(valData.columns[0], axis=1)\n",
    "testData = testData.drop(testData.columns[0], axis=1)\n",
    "\n",
    "#transfer label into 0/1,SUPPORTS-1,REFUTES-0\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(trainData['Label'])\n",
    "trainData['Label'] =labelencoder.transform(trainData['Label'])\n",
    "valData['Label'] =labelencoder.transform(valData['Label'])\n",
    "testData['Label'] =labelencoder.transform(testData['Label'])\n",
    "\n",
    "print(\"Training data size: {}\".format(trainData.shape))\n",
    "print(\"Test data size: {}\".format(testData.shape))\n",
    "print(\"Validation data size: {}\".format(valData.shape))\n",
    "print(\"Classes distribution:\\n{}\".format(trainData.Label.value_counts())) \n",
    "\n",
    "print(\"Some train examples: {}\".format(trainData.iloc[:3]))\n",
    "print(\"Some test examples: {}\".format(testData.iloc[:3]))\n",
    "print(\"Some validation examples: {}\".format(valData.iloc[:3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing text...\n",
      "Before:\n",
      "                                            Claim  \\\n",
      "0  Chris Hemsworth appeared in A Perfect Getaway.   \n",
      "1                         Roald Dahl is a writer.   \n",
      "2                       Roald Dahl is a governor.   \n",
      "\n",
      "                                            Evidence  ID  Label  \n",
      "0  2\\tHemsworth has also appeared in the science ...   3      1  \n",
      "1  0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...   7      1  \n",
      "2  0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...   8      0  \n",
      "After:\n",
      "                                               Claim  \\\n",
      "0  [chris, hemsworth, appeared, a, perfect, getaway]   \n",
      "1                              [roald, dahl, writer]   \n",
      "2                            [roald, dahl, governor]   \n",
      "\n",
      "                                            Evidence  ID  Label  \n",
      "0  [hemsworth, also, appeared, science, fiction, ...   3      1  \n",
      "1  [roald, dahl, british, novelist, short, story,...   7      1  \n",
      "2  [roald, dahl, british, novelist, short, story,...   8      0  \n",
      "Pre-processing completed!\n"
     ]
    }
   ],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;.:`\\-\\'\\\"]')\n",
    "GOOD_SYMBOLS_RE = re.compile('[^0-9a-zA-Z #+_]')\n",
    "#for example: -LSB- eˈlaða -RSB-\n",
    "REMOVE_SB = re.compile('-LSB-(.*?)-RSB-')\n",
    "REMOVE_RB = re.compile('-LRB-|-RRB-')\n",
    "# for example: -LRB- 1944 -RRB-\n",
    "RB_PAIRS = re.compile('-LRB-(.*?)-RRB-') \n",
    "\n",
    "\n",
    "try:\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def lower(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Transforms given text to lower case.\n",
    "    Example:\n",
    "    Input: 'I really like New York city'\n",
    "    Output: 'i really like new your city'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.lower()\n",
    "\n",
    "def replace_special_characters(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces special characters, such as paranthesis,\n",
    "    with spacing character\n",
    "    \"\"\"\n",
    "\n",
    "    return REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "\n",
    "def replace_br(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Replaces br characters\n",
    "    \"\"\"\n",
    "\n",
    "    return text.replace(' br ', '')\n",
    "\n",
    "def remove_SB_text(text):\n",
    "    \"\"\"\n",
    "    Removes -LSB- and -RSB- pairs in the text\n",
    "    \"\"\"\n",
    "    return REMOVE_SB.sub('', text)\n",
    "\n",
    "def filter_out_uncommon_symbols(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any special character that is not in the\n",
    "    good symbols list (check regular expression)\n",
    "    \"\"\"\n",
    "\n",
    "    return GOOD_SYMBOLS_RE.sub('', text)\n",
    "\n",
    "def remove_RB_text(text):\n",
    "    \"\"\"\n",
    "    Removes -LRB- -RRB- or -LRB- -RRB- pairs in the text\n",
    "    \"\"\"\n",
    "    sentences = re.findall(RB_PAIRS, text)\n",
    "    for sent in sentences: \n",
    "        if re.search(GOOD_SYMBOLS_RE, sent) is not None:\n",
    "            text = RB_PAIRS.sub('', text, 1)\n",
    "        else:\n",
    "            text = REMOVE_RB.sub('', text, 2)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    return ' '.join([x for x in text.split() if x and x not in STOPWORDS])\n",
    "\n",
    "\n",
    "def strip_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Removes any left or right spacing (including carriage return) from text.\n",
    "    Example:\n",
    "    Input: '  This assignment is cool\\n'\n",
    "    Output: 'This assignment is cool'\n",
    "    \"\"\"\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "def split_text(text: str) -> str:\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "PREPROCESSING_PIPELINE = [\n",
    "                          remove_SB_text,\n",
    "                          remove_RB_text,\n",
    "                          replace_special_characters,\n",
    "                          replace_br,\n",
    "                          filter_out_uncommon_symbols,\n",
    "                          remove_stopwords,\n",
    "                          lower,\n",
    "                          strip_text,\n",
    "                          split_text\n",
    "                          ]\n",
    "\n",
    "\n",
    "def text_prepare(text: str,filter_methods=PREPROCESSING_PIPELINE):\n",
    "    return reduce(lambda x, f: f(x), filter_methods, text)\n",
    "\n",
    "print('Pre-processing text...')\n",
    "print('Before:\\n{}'.format(trainData[:3]))\n",
    "\n",
    "# Replace each sentence with its pre-processed version\n",
    "trainData.Claim = trainData.Claim.apply(lambda x: text_prepare(x))\n",
    "#forexample: remove \\t in '2\\tHemsworth has also appeared'\n",
    "trainData.Evidence = trainData.Evidence.apply(lambda x: x.split('\\t')[1])\n",
    "trainData.Evidence = trainData.Evidence.apply(lambda x: text_prepare(x))\n",
    "\n",
    "testData.Claim = testData.Claim.apply(lambda x: text_prepare(x))\n",
    "testData.Evidence = testData.Evidence.apply(lambda x: x.split('\\t')[1])\n",
    "testData.Evidence = testData.Evidence.apply(lambda x: text_prepare(x))\n",
    "\n",
    "valData.Claim = valData.Claim.apply(lambda x: text_prepare(x))\n",
    "valData.Evidence = valData.Evidence.apply(lambda x: x.split('\\t')[1])\n",
    "valData.Evidence = valData.Evidence.apply(lambda x: text_prepare(x))\n",
    "\n",
    "\n",
    "print('After:\\n{}'.format(trainData[:3]))\n",
    "print(\"Pre-processing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train claim data:  (121740,)\n",
      "Train evidence data:  (121740,)\n",
      "Train label:  (121740,)\n",
      "Validation claim data:  (7165,)\n",
      "Validation evidence data:  (7165,)\n",
      "Validation label:  (7165,)\n",
      "Test claim data:  (7189,)\n",
      "Test evidence data:  (7189,)\n",
      "Test label:  (7189,)\n"
     ]
    }
   ],
   "source": [
    "x_train_Claim = trainData.Claim.values\n",
    "x_train_Evidence = trainData.Evidence.values\n",
    "y_train = trainData.Label.values\n",
    "x_test_Claim = testData.Claim.values\n",
    "x_test_Evidence = testData.Evidence.values\n",
    "y_test = testData.Label.values\n",
    "x_val_Claim = valData.Claim.values\n",
    "x_val_Evidence = valData.Evidence.values\n",
    "y_val = valData.Label.values\n",
    "\n",
    "print('Train claim data: ', x_train_Claim.shape)\n",
    "print('Train evidence data: ', x_train_Evidence.shape)\n",
    "print('Train label: ', y_train.shape)\n",
    "print('Validation claim data: ', x_val_Claim.shape)\n",
    "print('Validation evidence data: ', x_val_Evidence.shape)\n",
    "print('Validation label: ', y_val.shape)\n",
    "print('Test claim data: ', x_test_Claim.shape)\n",
    "print('Test evidence data: ', x_test_Evidence.shape)\n",
    "print('Test label: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 257810/257810 [00:00<00:00, 496160.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index -> Word vocabulary size: 31448\n",
      "Word -> Index vocabulary size: 31448\n",
      "The corpus length: 31448\n",
      "Some words: [('hemsworth', 1), ('appeared', 2), ('a', 3), ('perfect', 4), ('getaway', 5), ('roald', 6), ('dahl', 7), ('writer', 8), ('governor', 9), ('ireland', 10)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function definition\n",
    "def build_vocabulary(df: pd.DataFrame) -> (Dict[int, str],Dict[str, int],List[str]):\n",
    "\n",
    "    idx_to_word = OrderedDict()\n",
    "    word_to_idx = OrderedDict()\n",
    "    curr_idx = 0\n",
    "    \n",
    "    for sentence in tqdm(df.values):\n",
    "        tokens = sentence\n",
    "        for token in tokens:\n",
    "          if token not in word_to_idx:\n",
    "              word_to_idx[token] = curr_idx\n",
    "              idx_to_word[curr_idx] = token\n",
    "              curr_idx += 1\n",
    "\n",
    "    word_listing = list(idx_to_word.values())\n",
    "    return idx_to_word, word_to_idx, word_listing\n",
    "\n",
    "corpus = pd.concat([trainData.Claim,trainData.Evidence,valData.Claim,valData.Evidence],ignore_index=True)\n",
    "idx_to_word, word_to_idx, word_listing = build_vocabulary(corpus)\n",
    "\n",
    "print('Index -> Word vocabulary size: {}'.format(len(idx_to_word)))\n",
    "print('Word -> Index vocabulary size: {}'.format(len(word_to_idx)))\n",
    "print('The corpus length: {}'.format(len(word_listing)))\n",
    "print('Some words: {}'.format([(idx_to_word[idx], idx) for idx in np.arange(10) + 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the glove\n",
    "embedding_dimension = 50\n",
    "download_path = \"glove-wiki-gigaword-{}\".format(embedding_dimension)\n",
    "\n",
    "try:\n",
    "    embedding_model = gloader.load(download_path)\n",
    "except ValueError as e:\n",
    "    print(\"Invalid embedding model name! Check the embedding dimension:\")\n",
    "    print(\"Glove: 50, 100, 200, 300\")\n",
    "    raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total OOV terms: 1949 (6.20%)\n"
     ]
    }
   ],
   "source": [
    "# check oov terms \n",
    "def check_OOV_terms(embedding_model,word_listing):\n",
    "    embedding_vocabulary = set(embedding_model.key_to_index.keys())\n",
    "    oov = set(word_listing).difference(embedding_vocabulary)\n",
    "    return list(oov)\n",
    "\n",
    "oov_terms = check_OOV_terms(embedding_model, word_listing)\n",
    "print(\"Total OOV terms: {0} ({1:.2f}%)\".format(len(oov_terms), float(len(oov_terms)) / len(word_listing)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary length: 31450\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "oov_token = \"<OOV>\"\n",
    "tokenizer = Tokenizer(oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "vocabLength = len(tokenizer.word_index)+1 \n",
    "print(\"Tokenizer vocabulary length: {}\".format(vocabLength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulid the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31449/31449 [00:00<00:00, 281469.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (31450, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function definition\n",
    "\n",
    "def build_embedding_matrix(embedding_model: gensim.models.keyedvectors.KeyedVectors,\n",
    "                           embedding_dimension: int,\n",
    "                           word_to_idx: Dict[str, int]) -> np.ndarray:\n",
    "\n",
    "    embedding_matrix = np.zeros((len(word_to_idx)+1, embedding_dimension))\n",
    "    for word, i in tqdm(word_to_idx.items()):\n",
    "        try:\n",
    "            embedding_vector = embedding_model[word]\n",
    "        except (KeyError, TypeError):\n",
    "            embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dimension)\n",
    "\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "embedding_matrix = build_embedding_matrix(embedding_model, embedding_dimension, tokenizer.word_index)\n",
    "\n",
    "print(\"Embedding matrix shape: {}\".format(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length is: 91 words\n",
      "[[ 267. 2253.   68.   26.  975. 5565.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.]\n",
      " [5190. 4133.   99.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.]\n",
      " [5190. 4133.  831.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.]]\n",
      "X claim train shape:  (121740, 91)\n",
      "X evidence train shape:  (121740, 91)\n",
      "Y train shape:  (121740,)\n",
      "X claim val shape:  (7165, 91)\n",
      "X evidence val shape:  (7165, 91)\n",
      "Y val shape:  (7165,)\n",
      "X claim test shape:  (7189, 91)\n",
      "X evidence test shape:  (7189, 91)\n",
      "Y test shape:  (7189,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "def convert_text(texts, tokenizer,max_seq_length):\n",
    "\n",
    "    text_ids = tokenizer.texts_to_sequences(texts)\n",
    "    text_ids = pad_sequences(text_ids, padding='post', truncating='post', maxlen=max_seq_length,dtype='float32')\n",
    "    # text_ids = [seq + [0] * (max_seq_length - len(seq)) for seq in text_ids]\n",
    "    # text_ids = np.array([seq[:max_seq_length] for seq in text_ids])\n",
    "\n",
    "    return text_ids\n",
    "\n",
    "max_seq_length = max(len(x) for x in corpus)\n",
    "print(\"Max sentence length is: {} words\".format(max_seq_length))\n",
    "\n",
    "# Train\n",
    "x_train_Claim = convert_text(x_train_Claim, tokenizer,max_seq_length)\n",
    "x_train_Evidence = convert_text(x_train_Evidence, tokenizer,max_seq_length)\n",
    "\n",
    "print(x_train_Claim[:3])\n",
    "print('X claim train shape: ', x_train_Claim.shape)\n",
    "print('X evidence train shape: ', x_train_Evidence.shape)\n",
    "print('Y train shape: ', y_train.shape)\n",
    "\n",
    "# Val\n",
    "x_val_Claim = convert_text(x_val_Claim, tokenizer,max_seq_length)\n",
    "x_val_Evidence = convert_text(x_val_Evidence, tokenizer,max_seq_length)\n",
    "print('X claim val shape: ', x_val_Claim.shape)\n",
    "print('X evidence val shape: ', x_val_Evidence.shape)\n",
    "print('Y val shape: ', y_val.shape)\n",
    "\n",
    "# Test\n",
    "x_test_Claim = convert_text(x_test_Claim, tokenizer,max_seq_length)\n",
    "x_test_Evidence = convert_text(x_test_Evidence, tokenizer,max_seq_length)\n",
    "print('X claim test shape: ', x_test_Claim.shape)\n",
    "print('X evidence test shape: ', x_test_Evidence.shape)\n",
    "print('Y test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "#Cosine similarity\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "\n",
    "# merging strategy and Concatenate cosine similarity to the result\n",
    "def merge_multi_inputs(strategy,input1,input2):\n",
    "\n",
    "  distance = Lambda(cosine_distance, output_shape=cos_dist_output_shape)([input1, input2])\n",
    "  merge = []\n",
    "  if strategy == 'concatenation':\n",
    "    merge = Concatenate()([input1, input2])\n",
    "  elif strategy == 'sum':\n",
    "    merge = Add()([input1, input2])\n",
    "  elif strategy == 'mean':\n",
    "    merge = Average()([input1, input2])\n",
    "  #concatenate cosine similarity with the claim and evidence\n",
    "  merge = Concatenate()([merge, distance])\n",
    "  return merge\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lstm: take the last state as the sentence embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model1(merging_stragegy : str,compile_info: Dict) -> keras.Model:\n",
    "\n",
    "    #input layer\n",
    "    claimInput=Input(shape=(max_seq_length,))\n",
    "    embedding_layer_claim = Embedding(input_dim = vocabLength,\n",
    "                                output_dim = embedding_dimension,\n",
    "                                weights= [embedding_matrix],\n",
    "                                input_length=max_seq_length,\n",
    "                                mask_zero = True,\n",
    "                                name = \"embedding_layer_claim\")(claimInput)\n",
    "    eviInput=Input(shape=(max_seq_length,))\n",
    "    embedding_layer_evi = Embedding(input_dim = vocabLength,\n",
    "                                output_dim = embedding_dimension,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_seq_length,\n",
    "                                mask_zero = True,\n",
    "                                name = \"embedding_layer_evi\")(eviInput)\n",
    "    #lstm layer\n",
    "    Lstm_layer_claim = Bidirectional(LSTM(64))(embedding_layer_claim)\n",
    "    Lstm_layer_evi = Bidirectional(LSTM(64))(embedding_layer_evi)\n",
    "\n",
    "    # merge claim + evidence + cosine similarity\n",
    "    merge_data = merge_multi_inputs(merging_stragegy,Lstm_layer_claim,Lstm_layer_evi)\n",
    "   \n",
    "    dense_output1 = Dense(units = 256, activation = \"relu\", name=\"dense_1\")(merge_data)\n",
    "    dense_output2 = Dense(units = 64, activation = \"relu\", name=\"dense_2\")(dense_output1)\n",
    "    dropout_output = Dropout(0.2)(dense_output2) #overfitting\n",
    "    last_output = Dense(units = 1, activation = \"sigmoid\", name=\"logits\")(dropout_output)\n",
    "\n",
    "    model = Model(inputs=[claimInput,eviInput], outputs=last_output)  \n",
    "    model.summary()\n",
    "    model.compile(**compile_info)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lstm: average all the output states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model2(merging_stragegy : str,compile_info: Dict) -> keras.Model:\n",
    "\n",
    "    #input layer  \n",
    "    claimInput=Input(shape=(max_seq_length,))\n",
    "    embedding_layer_claim = Embedding(input_dim = vocabLength,\n",
    "                                output_dim = embedding_dimension,\n",
    "                                weights= [embedding_matrix],\n",
    "                                input_length=max_seq_length,\n",
    "                                mask_zero = True,\n",
    "                                name = \"embedding_layer_claim\")(claimInput)\n",
    "    eviInput=Input(shape=(max_seq_length,))\n",
    "    embedding_layer_evi = Embedding(input_dim = vocabLength,\n",
    "                                output_dim = embedding_dimension,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_seq_length,\n",
    "                                mask_zero = True,\n",
    "                                name = \"embedding_layer_evi\")(eviInput)\n",
    "    #lstm layer\n",
    "    #return_sequence=True output shape:3d / return_sequence=flase output shape:2d\n",
    "    Lstm_layer_claim = Bidirectional(LSTM(64,return_sequences=True))(embedding_layer_claim)\n",
    "    Lstm_layer_evi = Bidirectional(LSTM(64,return_sequences=True))(embedding_layer_evi)\n",
    "    #average the output\n",
    "    average_claim = GlobalAveragePooling1D()(Lstm_layer_claim)\n",
    "    average_evi = GlobalAveragePooling1D()(Lstm_layer_evi)\n",
    "    # merge claim + evidence + cosine similarity\n",
    "    merge_data = merge_multi_inputs(merging_stragegy,average_claim,average_evi)\n",
    "    dense_output1 = Dense(units = 256, activation = \"relu\", name=\"dense_1\")(merge_data)\n",
    "    dense_output2 = Dense(units = 64, activation = \"relu\", name=\"dense_2\")(dense_output1)\n",
    "    dropout_output = Dropout(0.2)(dense_output2)\n",
    "    last_output = Dense(units = 1, activation = \"sigmoid\", name=\"logits\")(dropout_output)\n",
    "\n",
    "    model = Model(inputs=[claimInput,eviInput], outputs=last_output)\n",
    "    model.summary()\n",
    "    model.compile(**compile_info)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP：reshape the 3D input to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model(merging_stragegy : str,compile_info: Dict) -> keras.Model:\n",
    "\n",
    "    # input layer\n",
    "    claimInput=Input(shape=(max_seq_length,))\n",
    "    embedding_layer_claim = Embedding(input_dim = vocabLength,\n",
    "                                output_dim = embedding_dimension,\n",
    "                                weights= [embedding_matrix],\n",
    "                                input_length=max_seq_length,\n",
    "                                mask_zero = True,\n",
    "                                name = \"embedding_layer_claim\")(claimInput)\n",
    "    eviInput=Input(shape=(max_seq_length,))\n",
    "    embedding_layer_evi = Embedding(input_dim = vocabLength,\n",
    "                                output_dim = embedding_dimension,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_seq_length,\n",
    "                                mask_zero = True,\n",
    "                                name = \"embedding_layer_evi\")(eviInput)\n",
    "    # reshape the 3D input from `[batch_size, max_tokens, embedding_dim]` to `[batch_size, max_tokens * embedding_dim]`\n",
    "    reshape_claim = Reshape((embedding_layer_claim.shape[2] * embedding_layer_claim.shape[1],))(embedding_layer_claim)\n",
    "    reshape_evi = Reshape((embedding_layer_evi.shape[2] * embedding_layer_evi.shape[1],))(embedding_layer_evi)\n",
    "    # merge claim + evidence + cosine similarity \n",
    "    merge_data = merge_multi_inputs(merging_stragegy,reshape_claim,reshape_evi)\n",
    "    dense_output1 = Dense(units = 256, activation = \"relu\", name=\"dense_1\")(merge_data)\n",
    "    dense_output2 = Dense(units = 64, activation = \"relu\", name=\"dense_2\")(dense_output1)\n",
    "    dropout_output = Dropout(0.2)(dense_output2)\n",
    "    last_output = Dense(units = 1, activation = \"sigmoid\", name=\"logits\")(dropout_output)\n",
    "\n",
    "    model = Model(inputs=[claimInput,eviInput], outputs=last_output)\n",
    "    model.summary()\n",
    "    model.compile(**compile_info)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOV:Compute the sentence embedding as the mean of its token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bov_model(merging_stragegy : str,compile_info: Dict) -> keras.Model:\n",
    "\n",
    "    #input layer\n",
    "    claimInput=Input(shape=(max_seq_length,))\n",
    "    embedding_layer_claim = Embedding(input_dim = vocabLength,\n",
    "                                output_dim = embedding_dimension,\n",
    "                                weights= [embedding_matrix],\n",
    "                                input_length=max_seq_length,\n",
    "                                mask_zero = True,\n",
    "                                name = \"embedding_layer_claim\")(claimInput)\n",
    "    eviInput=Input(shape=(max_seq_length,))\n",
    "    embedding_layer_evi = Embedding(input_dim = vocabLength,\n",
    "                                output_dim = embedding_dimension,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=max_seq_length,\n",
    "                                mask_zero = True,\n",
    "                                name = \"embedding_layer_evi\")(eviInput)\n",
    "    # compute the mean\n",
    "    average_claim = GlobalAveragePooling1D()(embedding_layer_claim)\n",
    "    average_evi = GlobalAveragePooling1D()(embedding_layer_evi)\n",
    "    # merge claim + evidence + cosine similarity\n",
    "    merge_data = merge_multi_inputs(merging_stragegy,average_claim,average_evi)\n",
    "   \n",
    "    dense_output1 = Dense(units = 256, activation = \"relu\", name=\"dense_1\")(merge_data)\n",
    "    dense_output2 = Dense(units = 64, activation = \"relu\", name=\"dense_2\")(dense_output1)\n",
    "    dropout_output = Dropout(0.2)(dense_output2)\n",
    "    last_output = Dense(units = 1, activation = \"sigmoid\", name=\"logits\")(dropout_output)\n",
    "\n",
    "    model = Model(inputs=[claimInput,eviInput], outputs=last_output)\n",
    "    model.summary()\n",
    "    model.compile(**compile_info)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_strategy = [\n",
    "    'concatenation', \n",
    "    'sum',\n",
    "    'mean'\n",
    "]\n",
    "\n",
    "compile_info = {\n",
    "    'optimizer': keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'metrics': ['accuracy'],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy and loss\n",
    "def show_history(history: keras.callbacks.History):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    #accuracy image\n",
    "    plt.plot(epochs,acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.figure()\n",
    "\n",
    "    #loss image\n",
    "    plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model: keras.Model,\n",
    "                x_train_Claim: np.ndarray,\n",
    "                x_train_Evidence: np.ndarray,\n",
    "                y_train: np.ndarray,\n",
    "                x_val_Claim: np.ndarray,\n",
    "                x_val_Evidence: np.ndarray,\n",
    "                y_val: np.ndarray,\n",
    "                training_info: Dict):\n",
    "\n",
    "    print(\"Start training! \\nParameters: {}\".format(training_info))\n",
    "    history = model.fit(x=(x_train_Claim,x_train_Evidence), y=y_train,\n",
    "                        validation_data=([x_val_Claim,x_val_Evidence], y_val),\n",
    "                        **training_info)\n",
    "    print(\"Training completed! Showing history...\")\n",
    "\n",
    "    show_history(history)\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_data(model: keras.Model,\n",
    "                 x_test_Claim: np.ndarray,\n",
    "                 x_test_Evidence:np.ndarray,\n",
    "                 prediction_info: Dict) -> np.ndarray:\n",
    "\n",
    "    print('Starting prediction: \\n{}'.format(prediction_info))\n",
    "    print('Predicting on {} samples'.format(x_test_Claim.shape[0]))\n",
    "\n",
    "    predictions = model.predict([x_test_Claim,x_test_Evidence], **prediction_info)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluate_predictions(predictions: np.ndarray,\n",
    "                         y: np.ndarray,\n",
    "                         metrics: List[Callable],\n",
    "                         metric_names: List[str]):\n",
    "\n",
    "    assert len(metrics) == len(metric_names)\n",
    "\n",
    "    print(\"Evaluating predictions! Total samples: \", y.shape[0])\n",
    "\n",
    "    metric_info = {}\n",
    "\n",
    "    for metric, metric_name in zip(metrics, metric_names):\n",
    "        metric_value = metric(y_pred=predictions, y_true=y)\n",
    "        metric_info[metric_name] = metric_value\n",
    "\n",
    "    return metric_info\n",
    "\n",
    "\n",
    "# Training info\n",
    "training_info = {\n",
    "    'verbose': 1,\n",
    "    'epochs': 30,\n",
    "    'batch_size': 128,\n",
    "    'callbacks': [keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                patience=10,\n",
    "                                                restore_best_weights=True)]\n",
    "}\n",
    "# prediction info\n",
    "prediction_info = {\n",
    "    'batch_size': 128,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "# Evaluation info\n",
    "metrics = [\n",
    "    accuracy_score,\n",
    "    partial(f1_score, pos_label=1, average='binary')\n",
    "]\n",
    "metric_names = [\n",
    "    \"accuracy\",\n",
    "    \"binary_f1\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-input classification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_evaluation(testLable,testPrediction):\n",
    "    report = classification_report(testLable, testPrediction,zero_division=True,labels=[0,1], target_names=[\"REFUTES\", \"SUPPORTS\"])\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claim verification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def print_verifEvaluation(testPrediction):\n",
    "    testDataCopy = copy.deepcopy(testData)\n",
    "    testDataCopy.insert(4,'Prediction',testPrediction)\n",
    "    rule = lambda x: x.mode().iat[0]\n",
    "    voting_test_label = testDataCopy.groupby('ID')['Label'].apply(rule).reset_index(name='Majority_Label')\n",
    "    voting_predict_label = testDataCopy.groupby('ID')['Prediction'].apply(rule).reset_index(name='Majority_Label')\n",
    "\n",
    "    report = classification_report(voting_test_label['Majority_Label'], voting_predict_label['Majority_Label'],zero_division=True,labels=[0,1], target_names=[\"REFUTES\", \"SUPPORTS\"])\n",
    "    print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose one model and try all merging strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 91)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 91)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_claim (Embeddin (None, 91, 50)       1572500     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer_evi (Embedding) (None, 91, 50)       1572500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4550)         0           embedding_layer_claim[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 4550)         0           embedding_layer_evi[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9100)         0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 9101)         0           concatenate[0][0]                \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          2330112     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           16448       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "logits (Dense)                  (None, 1)            65          dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,491,625\n",
      "Trainable params: 5,491,625\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Start training! \n",
      "Parameters: {'verbose': 1, 'epochs': 30, 'batch_size': 128, 'callbacks': [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x0000012D94B47280>]}\n",
      "Epoch 1/30\n",
      "952/952 [==============================] - 58s 61ms/step - loss: 0.5322 - accuracy: 0.7561 - val_loss: 0.6775 - val_accuracy: 0.5969\n",
      "Epoch 2/30\n",
      "952/952 [==============================] - 61s 64ms/step - loss: 0.4585 - accuracy: 0.7908 - val_loss: 0.6689 - val_accuracy: 0.6331\n",
      "Epoch 3/30\n",
      "952/952 [==============================] - 63s 66ms/step - loss: 0.4102 - accuracy: 0.8127 - val_loss: 0.7078 - val_accuracy: 0.6415\n",
      "Epoch 4/30\n",
      "952/952 [==============================] - 65s 69ms/step - loss: 0.3707 - accuracy: 0.8296 - val_loss: 0.7225 - val_accuracy: 0.6606\n",
      "Epoch 5/30\n",
      "952/952 [==============================] - 64s 67ms/step - loss: 0.3356 - accuracy: 0.8432 - val_loss: 0.7196 - val_accuracy: 0.6565\n",
      "Epoch 6/30\n",
      "952/952 [==============================] - 63s 66ms/step - loss: 0.3027 - accuracy: 0.8571 - val_loss: 0.8495 - val_accuracy: 0.6523\n",
      "Epoch 7/30\n",
      "952/952 [==============================] - 66s 69ms/step - loss: 0.2742 - accuracy: 0.8690 - val_loss: 0.9647 - val_accuracy: 0.6571\n",
      "Epoch 8/30\n",
      "952/952 [==============================] - 61s 64ms/step - loss: 0.2469 - accuracy: 0.8804 - val_loss: 1.0862 - val_accuracy: 0.6607\n",
      "Epoch 9/30\n",
      "952/952 [==============================] - 65s 68ms/step - loss: 0.2250 - accuracy: 0.8898 - val_loss: 1.2609 - val_accuracy: 0.6657\n",
      "Epoch 10/30\n",
      "952/952 [==============================] - 63s 66ms/step - loss: 0.2046 - accuracy: 0.8997 - val_loss: 1.4286 - val_accuracy: 0.6646\n",
      "Epoch 11/30\n",
      "952/952 [==============================] - 63s 66ms/step - loss: 0.1886 - accuracy: 0.9063 - val_loss: 1.5728 - val_accuracy: 0.6596\n",
      "Epoch 12/30\n",
      "952/952 [==============================] - 64s 67ms/step - loss: 0.1755 - accuracy: 0.9127 - val_loss: 1.7271 - val_accuracy: 0.6662\n",
      "Training completed! Showing history...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction: \n",
      "{'batch_size': 128, 'verbose': 1}\n",
      "Predicting on 7189 samples\n",
      "57/57 [==============================] - 1s 10ms/step\n",
      "Evaluating predictions! Total samples:  7189\n",
      "Metrics info: \n",
      "{'accuracy': 0.6215050772012798, 'binary_f1': 0.7094500800854243}\n",
      "Multi-input classification evaluation: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     REFUTES       0.80      0.32      0.46      3583\n",
      "    SUPPORTS       0.58      0.92      0.71      3606\n",
      "\n",
      "    accuracy                           0.62      7189\n",
      "   macro avg       0.69      0.62      0.58      7189\n",
      "weighted avg       0.69      0.62      0.58      7189\n",
      "\n",
      "Claim verification evaluation: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     REFUTES       0.80      0.33      0.46      3304\n",
      "    SUPPORTS       0.58      0.92      0.71      3309\n",
      "\n",
      "    accuracy                           0.62      6613\n",
      "   macro avg       0.69      0.62      0.59      6613\n",
      "weighted avg       0.69      0.62      0.59      6613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ms in merging_strategy:\n",
    "    print('==============================={}=================================='.format(ms))\n",
    "    model = create_mlp_model('concatenation',compile_info) \n",
    "    model = train_model(model=model, x_train_Claim=x_train_Claim, x_train_Evidence=x_train_Evidence,y_train=y_train,\n",
    "                        x_val_Claim=x_val_Claim,x_val_Evidence=x_val_Evidence, y_val=y_val, training_info=training_info)\n",
    "    test_predictions = predict_data(model=model, x_test_Claim=x_test_Claim,x_test_Evidence=x_test_Evidence,\n",
    "                                        prediction_info=prediction_info)\n",
    "    test_predictions = np.round(test_predictions,0).astype(np.int32)\n",
    "    metric_info = evaluate_predictions(predictions=test_predictions,\n",
    "                                    y=y_test,\n",
    "                                    metrics=metrics,\n",
    "                                    metric_names=metric_names)\n",
    "    print('Metrics info: \\n{}'.format(metric_info))\n",
    "    print('Multi-input classification evaluation: \\n')\n",
    "    print_evaluation(y_test,test_predictions)\n",
    "    print('Claim verification evaluation: \\n')\n",
    "    print_verifEvaluation(test_predictions)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9d6321f44481eb46a73bf81dc16280167257041196987c880b4339fc7b585d76"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
